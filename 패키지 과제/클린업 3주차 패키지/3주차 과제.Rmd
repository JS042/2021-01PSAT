---
title: "3주차 과제"
author: "위재성"
output: html_document
---

## Chapter 1  
  
  
#### 문제 0 기본 세팅. 
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(data.table)
library(gridExtra)

setwd("D:/WJS/Documents/package/3st week")
data = fread('data.csv')
test = fread('test.csv')
```

#### 문제 1  
bmi(bmi 지수) 변수를 numeric 자료형으로 바꾸고 NA 값을 mean imputation 으로 채우세요.

```{r warning=FALSE}
data$bmi = as.numeric(data$bmi)
data$bmi = replace_na(data$bmi, mean(data$bmi,na.rm=T))
```

#### 문제 2
문자형 (character) 변수를 명목형 변수 (factor)로 바꾸세요.

```{r}
data <- data %>% 
  lapply(function(x) if(is.character(x)==T) as.factor(x) else(x)) %>% 
  as.data.frame
```

#### 문제 3
id 변수를 제거하세요.

```{r}
data <- data %>% select(-id)
```

#### 문제 4
타겟 stoke값 별로 범주형 변수의 분포를 다음과 같이 시각화 하고 간단히 해석해보세요.

```{r warning=FALSE}
s1 <- data %>% 
  filter(stroke ==1) %>% 
  select(which(sapply(data,is.factor)),
         hypertension,
         heart_disease) %>%
  gather(variable,value) %>% 
  ggplot(aes(x=variable,fill=value)) +
  geom_bar(position='fill',alpha=0.5) +
  coord_flip() +
  theme_classic() +
  labs(title = 'Stroke : 1', fill='',y='') +
  theme(legend.position = 'bottom', 
        plot.title = element_text(hjust=0.5),
        legend.text = element_text(size=5))
  
s0 <- data %>% 
  filter(stroke ==0) %>% 
  select(which(sapply(data,is.factor)),
         hypertension,
         heart_disease) %>%
  gather(variable,value) %>% 
  ggplot(aes(x=variable,fill=value)) +
  geom_bar(position='fill',alpha=0.5) +
  coord_flip() +
  theme_classic() +
  labs(title = 'Stroke : 0', fill='',y='') +
  theme(legend.position = 'bottom', 
        plot.title = element_text(hjust=0.5),
        legend.text = element_text(size=5))  
  

grid.arrange(s1,s0,ncol=2,widths=c(10,10))
```

뇌졸중이 있는 경우에는 없는 경우보다 흡연, 고혈압, 심장질환 비율이 상대적으로 높고 결혼한 적 있는 사람들의 비율 또한 더 높다는 걸 알 수 있습니다.

#### 문제 5
타겟 stroke값 별로 수치형 변수의 분포를 다음과 같이 시각화하고 간단히 해석해보세요.

```{r}
s1 <- data %>% 
  filter(stroke ==1) %>% 
  select(age,avg_glucose_level,bmi) %>%
  gather(variable,value) %>% 
  ggplot(aes(x=value,color=variable)) +
  geom_density() +
  theme_classic() +
  labs(title = 'Stroke : 1') +
  theme(plot.title = element_text(hjust=0.5))

s0 <- data %>% 
  filter(stroke ==0) %>% 
  select(age,avg_glucose_level,bmi) %>%
  gather(variable,value) %>% 
  ggplot(aes(x=value,color=variable)) +
  geom_density() +
  theme_classic() +
  labs(title = 'Stroke : 0') +
  theme(plot.title = element_text(hjust=0.5))

grid.arrange(s1,s0,ncol=1)
```

뇌졸중이 있는 경우가 없는 경우보다 나이 변수의 분포가 상대적으로 오른쪽으로 치우쳐저 있습니다.  
즉, 뇌졸중이 있는 그룹의 사람들이 나이가 비교적 더 많다는 걸 알 수 있습니다.

  
  
#### 문제 6
타겟 변수와 범주형 변수에 대한 카이스퀘어 독립성 검정을 진행하고 다음과 같이 출력하세요.

```{r warning=FALSE}
data_s <- data %>% select(-c(age,avg_glucose_level,bmi,stroke))
chitest <- data.frame(cate_Var=names(data_s),chi=NA)

for (i in 1:7)
{
  result <- xtabs(formula = ~data_s[,i]+stroke,data=data) %>% 
    chisq.test()
  chitest[i,2] <- ifelse(result$p.value<0.05,'denied','accpet')
}
print(chitest)
```

#### 문제 7
카이스퀘어 독립성 검정에서 가설을 기각하지 못한 범주형 변수를 제거하세요.

```{r}
data <- data %>% select(-c(gender,Residence_type))
```

#### 문제 8
train data에서 했던 전처리 방법들을 사용하여 전처리 하세요.

```{r warning=FALSE}
test$bmi = as.numeric(test$bmi)
test$bmi = replace_na(test$bmi, mean(test$bmi,na.rm=T))

test <- test %>% 
  lapply(function(x) if(is.character(x)==T) as.factor(x) else(x)) %>% 
  as.data.frame

test <- test %>% select(-c(id,gender,Residence_type))
```

## Chapter 2

```{r include=FALSE}
library(catboost)
library(caret)
library(MLmetrics)
```

#### 문제 0
Catboost 모델의 특성 및 대표적인 파라미터에 대해 간단히 설명하세요.
  
Catboost 모델은 범주형 변수가 많은 데이터에서 유용하게 쓰입니다.  
범주형 변수를 따로 전처리 하지 않아도 사용할 수 있기 때문이죠.  
대표적인 파라미터로는 loss_function이 있습니다.  
loss_function은 학습 기준을 제시하는 파라미터입니다.
    

#### 문제 1
expand.grid를 사용하여 다음과 같은 데이터 프레임을 만드세요.
```{r}
logloss_cb = expand.grid(depth=c(4,6,8),
                         iterations = c(100,200),
                         logloss=NA)
```


#### 문제 2
Catboost에 대해 depth와 iteration 파라미터 튜닝을 위한 grid search 5 fold CV를 진행하세요.

```{r}
set.seed(1234)
logloss <- c()
train_ind <- createFolds(data$stroke,k=5)
start = Sys.time()
for (i in 1:6)
{
  for (j in 1:5)
  {
    trainf <- data[train_ind[[j]],]
    testf <- data[-train_ind[[j]],]
    
    train_pool <- catboost.load_pool(data=trainf %>% select(-stroke),
                                    label = trainf$stroke)
    
    fit_params <- list(loss_function = 'Logloss', 
                   iterations = logloss_cb[i,2],
                   depth = logloss_cb[i,1], 
                   random_seed=1234)
  
    model <- catboost.train(train_pool, params=fit_params)
    
    testf_pool <- catboost.load_pool(data=testf %>% select(-stroke),
                                    label = testf$stroke)
    pred_testf <- catboost.predict(model,testf_pool)
    logloss[j] <- LogLoss(pred_testf,testf$stroke)
  }
  logloss_cb[i,3] <- mean(logloss)
}
end= Sys.time()
end-start
```


#### 문제 3
logloss_cb에서 가장 낮은 logloss 값의 행을 출력하세요.

```{r}
logloss_cb
best <- logloss_cb %>% filter(logloss == min(logloss))
best
```


#### 문제 4
가장 낮은 logloss 값의 파라미터로 전체 데이터를 학습시켜 test set에 대한 logloss 값을 구하세요.

```{r message=FALSE, warning=FALSE}
data_pool <- catboost.load_pool(data=data %>% select(-stroke),
                                    label = data$stroke)
    
fit_params <- list(loss_function = 'Logloss', 
                   iterations = best$iterations,
                   depth = best$depth, 
                   random_seed=1234)
  
model_best <- catboost.train(data_pool, params=fit_params)

test_pool <- catboost.load_pool(test %>% select(-stroke),
                                test$stroke)

pred_test <- catboost.predict(model_best,test_pool)
LogLoss(pred_test, test$stroke)
```


  
## Chapter 3

```{r include=FALSE}
library(factoextra)
library(cluster)
```
  
#### 문제 1
수치형 변수 (age, avg_glucose_level, bmi)에 대해 scale 함수로 정규화 스케일링을 하세요.
```{r}
data_scale <- 
  data %>% 
  select(age,avg_glucose_level,bmi) %>% 
  scale
```


#### 문제 2
fviz_nbclust 함수로 다음과 같이 시각화 한 뒤 적절한 K값이 무엇인지 설명하세요.

```{r}
grid.arrange(data_scale %>% fviz_nbclust(kmeans,method = "wss"),
             data_scale %>% fviz_nbclust(kmeans,method = "silhouette"),
             nrow=1)
```
  
`K=2`에서는 클러스터 내 분산이 가장 많이 줄어들지만 실루엣 계수가 너무 낮습니다.  
반면 `K=4`에서는 실루엣 계수가 가장 높지만 클러스터 내 분산이 별로 줄어들지 않습니다.  
그렇기에 실루엣 계수가 높고, 클러스터 내 분산도 많이 줄어드는 `K=3`가 가장 적절합니다.


  
#### 문제 3
K-means 클러스터링을 한 후 다음과 같이 시각화하세요.

```{r}
set.seed(1234)
k3 = kmeans(data_scale,centers=3,nstart = 1,iter.max = 30)
fviz_cluster(k3,data=data_scale) +
  theme_classic()
```

#### 문제 4
사용한 변수인 age, avg_glucose_level(평균 혈당), bmi(bmi 수치)에 대해 다음과 같이 box_plot 시각화를 하고, 클러스터 별로 해석해보세요.

```{r}
col = c('#845ec2', '#ffc75f', '#ff5e78')

age = data %>% select(age) %>% 
  mutate(cluster=factor(k3$cluster)) %>% 
  ggplot(aes(x=cluster,y=age)) +
  geom_boxplot(fill=col,color=col,alpha=0.5,outlier.shape=NA) +
  stat_boxplot(geom='errorbar',color=col)+
  theme_classic()

glucose = data %>% select(avg_glucose_level) %>% 
  mutate(cluster=factor(k3$cluster)) %>% 
  ggplot(aes(x=cluster,y=avg_glucose_level)) +
  geom_boxplot(fill=col,color=col,alpha=0.5,outlier.shape=NA) +
  stat_boxplot(geom='errorbar',color=col)+
  theme_classic()

bmi = data %>% select(bmi) %>% 
  mutate(cluster=factor(k3$cluster)) %>% 
  ggplot(aes(x=cluster,y=bmi)) +
  geom_boxplot(fill=col,color=col,alpha=0.5,outlier.shape=NA) +
  stat_boxplot(geom='errorbar',color=col)+
  theme_classic()

grid.arrange(age,glucose,bmi,nrow=1)
```

1번 클러스터는 age, avg_glucose_level, bmi 모두 다른 클러스터에 비해 높습니다.  
2번 클러스터는 age, avg_glucose_level, bmi가 모두 상대적으로 낮습니다.  
3번 클러스터는 age와 bmi 수치가 상대적으로 높은 반면 avg_glucose_level은 클러스터들 중 가장 낮은 수치를 보입니다.